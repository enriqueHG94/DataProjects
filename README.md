# **PySpark Project**


### **First steps in the project:**

I have created the project and the folder with the resources I am going to use, then I have created the file with which I'm going to work with PySpark, in this first step, I have created the Spark session and I have read a file in CSV format, and later I have shown it on the screen.

### **Second steps in the project:**

I've created a new folder with a .py file, where I built the schema and assigned it to an object, then called the object in the main code.

### **Third stage of the project:**

I've created a new folder called services and a new .py file, where I've made a transformation that consists of creating a method that asks for a data frame as parameter and returns a new data frame, with a few columns already existing in the data frame and two new columns, then I have called the transformation in my main file and I have shown it on the screen.

### **Testing with assert:**

In this test I've created a new folder called test where I created two CSV files, a sample file and the expected result, to which I made a transformation that consisted of adding two new columns with their respective values, then I sorted the columns with sorted and used assert to check if the two data frames worked correctly.
